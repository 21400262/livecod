import csv
import json
import re

import requests

import numpy as np
import pandas as pd

confirmed_CSV_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'
deaths_CSV_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'
recovered_CSV_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'


def get_raw_data(url):
    with requests.Session() as s:
        download = s.get(url)
        decoded_content = download.content.decode('utf-8')
        cr = csv.reader(decoded_content.splitlines(), delimiter=',')
        my_list = list(cr)
        total_data = [row for row in my_list]
        return total_data


confirmed_total_data = get_raw_data(confirmed_CSV_URL)
deaths_total_data = get_raw_data(deaths_CSV_URL)
recovered_total_data = get_raw_data(recovered)

date = [i[:-3] for i in confirmed_total_data[0][4:]]
total_data = [{'date': date}]


for count in range(1, len(confirmed_total_data) - 1):  # len(confirmed_total_data) 464
    try:
        if (confirmed_total_data[count][1] == deaths_total_data[count][1] == recovered_total_data[count][1]):
            d = {
                'name': confirmed_total_data[count][1],
                'province/state': confirmed_total_data[count][0],
                'confirmed': confirmed_total_data[count][4:],
                'deaths': deaths_total_data[count][4:],
                'recovered': recovered_total_data[count][4:],
            }
            total_data.append(d)
    except IndexError:
        print("Index Error ignored")


def write_country_data(country):
    global date
    global total_data

    sum_confirmed = [0] * len(date)
    sum_deaths = [0] * len(date)
    sum_recovered = [0] * len(date)

    for i in total_data[1:]:
        if i['name'] == country:
            for j in range(len(date)):
                sum_confirmed[j] += int(i['confirmed'][j])
                sum_deaths[j] += int(i['deaths'][j])
                sum_recovered[j] += int(i['recovered'][j])

    total_data.append({
        'name': country,
        'province/state': 'total',
        'confirmed': sum_confirmed,
        'deaths': sum_deaths,
        'recovered': sum_recovered,
    })


countries = ['US', 'United Kingdom', 'Australia', 'Canada',
             'China', 'Congo', 'Denmark', 'France', 'Netherlands']

for country in countries:
    write_country_data(country)


with open('./data/HopkinsCoronaWorldData.js', 'w', encoding='utf-8') as make_file:
    json.dump(total_data, make_file, ensure_ascii=False, indent="\t")

data = ''
with open("./data/HopkinsCoronaWorldData.js", "r", encoding='UTF-8-sig') as f:
    while True:
        line = f.readline()
        if not line:
            break
        data += line
data = '//Auto-generated by Hopkins_world_data_parser.py\nvar hopkinsData = ' + data + ';'

with open("./data/HopkinsCoronaWorldData.js", "w", encoding='UTF-8-sig') as f_write:
    f_write.write(data)
